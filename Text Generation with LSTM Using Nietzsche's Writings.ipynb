{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWppJEv2ERVQ"
      },
      "source": [
        "# Long Short-term Memory for Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RBxDv-ERVS"
      },
      "source": [
        "This notebook uses LSTM neural network to generate text from Nietzsche's writings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vC0jdj6RERVS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.utils import get_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2W9-aTzERVU"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL8x1DjdERVU"
      },
      "source": [
        "### Get the data\n",
        "Nietzsche's writing dataset is available online. The following code download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "id": "06QxXBZDERVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b888133-ac68-47c6-b9aa-25945a8c2501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "\u001b[1m600901/600901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECFejNckERVV"
      },
      "source": [
        "### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JY47xw7-ERVV",
        "outputId": "6653a44b-550d-4498-c351-345393125262",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus length: 600893\n"
          ]
        }
      ],
      "source": [
        "print('corpus length:', len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "8Gwwa5wfERVW",
        "outputId": "be027113-52fb-45cf-ed40-8a7f04999a13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "supposing that truth is a woman--what then? is there not ground\n",
            "for suspecting that all philosophers, in so far as they have been\n",
            "dogmatists, have failed to understand women--that the terrible\n",
            "seriousness and clumsy importunity with which they have usually paid\n",
            "their addresses to truth, have been unskilled and unseemly methods for\n",
            "winning a woman? certainly she has never allowed herself to be won; and\n",
            "at present every kind of dogma stands with sad and discouraged mien--if,\n",
            "indeed, it stands at all!\n"
          ]
        }
      ],
      "source": [
        "print(text[10:513])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LPI4SkywERVX",
        "outputId": "19dcc29f-293e-4ef8-c436-280009ce2ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars: 57\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "# total nomber of characters\n",
        "print('total chars:', len(chars))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ibV0CydERVX"
      },
      "source": [
        "### Clean data\n",
        "\n",
        "We cut the text in sequences of maxlen characters with a jump size of 3.\n",
        "The features for each example is a matrix of size maxlen*num of chars.\n",
        "The label for each example is a vector of size num of chars, which represents the next character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "id": "R-jkujlsERVX"
      },
      "outputs": [],
      "source": [
        "# create (character, index) and (index, character) dictionary\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HEBUyXyBERVY",
        "outputId": "6dd9bf25-504f-462b-d205-eee88465eaa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sequences: 200285\n"
          ]
        }
      ],
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vecterization **This vectorization procedure includes a one-hot-encoding for each word, and therefore, an Embedding layer should not be used. If you want to use an Embedding layer. You will need to revise this block. **"
      ],
      "metadata": {
        "id": "5FGg1ShmWmSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ftcdv7S4ERVY",
        "outputId": "2d11f712-5979-4101-efb6-57b8fae4f85a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        }
      ],
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g04nzFKERVY"
      },
      "source": [
        "## The model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVWhFLcbERVZ"
      },
      "source": [
        "### Build the model - fill in this box"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRnIV0JtERVZ"
      },
      "source": [
        "we need a recurrent layer with input shape (maxlen, len(chars)) and a dense layer with output size  len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "id": "fzSVtBghERVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da542c6f-6943-4990-bfa6-ed9de2a59168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import layers, optimizers\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Input(shape=(maxlen, len(chars))))\n",
        "model.add(layers.LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers.SimpleRNN(32, return_sequences=False))\n",
        "model.add(layers.Dense(len(chars), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xte4grhqERVZ"
      },
      "source": [
        "### Inspect the model\n",
        "\n",
        "Use the `.summary` method to print a simple description of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xZYsX4p0ERVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c4f2c29f-1583-4682-b855-9b448c28c5b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │          \u001b[38;5;34m95,232\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m5,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)                  │           \u001b[38;5;34m1,881\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">95,232</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,881</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,265\u001b[0m (399.47 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,265</span> (399.47 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,265\u001b[0m (399.47 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,265</span> (399.47 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9q9AlZnERVa"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "QDLnDNk7ERVa"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "LSXssBV3ERVa"
      },
      "outputs": [],
      "source": [
        "class PrintLoss(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, _):\n",
        "        # Function invoked at end of each epoch. Prints generated text.\n",
        "        print()\n",
        "        print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "        for diversity in [0.5, 1.0]:\n",
        "            print('----- diversity:', diversity)\n",
        "\n",
        "            generated = ''\n",
        "            sentence = text[start_index: start_index + maxlen]\n",
        "            generated += sentence\n",
        "            print('----- Generating with seed: \"' + sentence + '\"')\n",
        "            sys.stdout.write(generated)\n",
        "\n",
        "            for i in range(400):\n",
        "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "                for t, char in enumerate(sentence):\n",
        "                    x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "                preds = model.predict(x_pred, verbose=0)[0]\n",
        "                next_index = sample(preds, diversity)\n",
        "                next_char = indices_char[next_index]\n",
        "\n",
        "                sentence = sentence[1:] + next_char\n",
        "\n",
        "                sys.stdout.write(next_char)\n",
        "                sys.stdout.flush()\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "id": "A-KBDhU0ERVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3ae9451-ed05-43ef-8cca-46bcc0e3fbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.1883 - loss: 2.9650\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" conceal\n",
            "under passionate grimaces what \"\n",
            " conceal\n",
            "under passionate grimaces what on on the and the sale sant the tunlisle the the porer the san for and the thin the the she the the sor to sens wis in momer se co tun poniphe thes an the bale lingenut an the the the her the s\n",
            "the in oh en in or in or the core the whe thee the os on the co ssond ant of ens ant, nruthe on the to and pe the menae\n",
            "de tho serals and on tor the bees mant denlr end nin the the le cores lr ond and ind t\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" conceal\n",
            "under passionate grimaces what \"\n",
            " conceal\n",
            "under passionate grimaces what anwelit\n",
            "printy äoxtoae bigtinu-si; anlos noim wes shes ter the the yqaondeunc,\n",
            "he secle euct, ost whet, kentano an the thip bal, sithiches napo an of ete,. jote,-lowais inshitaad\n",
            "sen as\n",
            "crier thas forchapl, ire,\n",
            "bererting on onl\n",
            "slpyemccalt\n",
            "w\" mon tor whed\n",
            "st iy patle\n",
            "bes\n",
            "thos the npioond.--;or, relpticf roug mangif tarencie aoniniged so8. aero?d\n",
            "se ok bwodu,yect se hemin a. cusgs ulg  amser hhaln\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 206ms/step - accuracy: 0.1883 - loss: 2.9648 - val_accuracy: 0.3197 - val_loss: 2.3742\n",
            "Epoch 2/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.3309 - loss: 2.3348\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"was revered as\n",
            "a sage and an oracle give\"\n",
            "was revered as\n",
            "a sage and an oracle giver and and\n",
            "incerith of in the sond and in and and lomaly and the herising in all with of be and thit ond tithe foil to there materte the the surticion and fricatitilitires and sordalice ars edand the preing and and thoucisting and and mole for ar and seatipation of in of the somaring in and and to praon and the mericicice the been the hereand matith to the poratith sand tore as of benterition, bit \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"was revered as\n",
            "a sage and an oracle give\"\n",
            "was revered as\n",
            "a sage and an oracle givedsr to which the\n",
            "thy\"\n",
            "the ysemin)\"\n",
            "oxindase th, aughal indonddllne id sssedirsal, simol] hos woruincige on, s creut euschyr ty iruteritok uncecarigisidicy thichse patsilcstiong thichmest\n",
            "therjest soist, lestan: irlitac catitibues- ae\n",
            "get on philate and and reonpteon aud-sichoad femtinticisl, an magom hand lablion plochatiss corspitediit hof marise be hald fur apdy hitice'teist in cikemusulpely\n",
            "mem\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 210ms/step - accuracy: 0.3309 - loss: 2.3347 - val_accuracy: 0.3688 - val_loss: 2.1780\n",
            "Epoch 3/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.3709 - loss: 2.1539\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"allowed to die out. in the same way\n",
            "ther\"\n",
            "allowed to die out. in the same way\n",
            "there and in the esperrot the destand and and esten which the some hald of hin the semaly and theer the monger the somences and bot mame the sendaly the ongersen the deversing in\n",
            "the aster the sile of the and and in all and exting the comcersion of pebtitiof and word and the must wish now of enderecal fralle and cresting the the sestion in conled the the\n",
            "the reacle and the mence, ald and expeneting on\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"allowed to die out. in the same way\n",
            "ther\"\n",
            "allowed to die out. in the same way\n",
            "theronoug revess indyte selit\n",
            "of andsenet for lrebes assand\n",
            "the consit of suqualectless\n",
            "as hi\n",
            "hithersed nemofre nok conpurion tund ard fathender in the bingy by the now gongenctuss min oth hopenserfy. tso lill on cinuty! semmer\n",
            "they mindes of peros fnist mecher thes alpevorisin slewdy ofean thereveptaly andured arfive the bledebyent wlouch groultder.y turcery actannon-. endanle4ferient is ave \n",
            "n eaed \n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 215ms/step - accuracy: 0.3709 - loss: 2.1538 - val_accuracy: 0.3943 - val_loss: 2.0654\n",
            "Epoch 4/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.3951 - loss: 2.0578\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"in person rejoices over every\n",
            "good opini\"\n",
            "in person rejoices over every\n",
            "good opining and so proted ene the moull the somerus the mone are at the mones corses, in the isselatich ho senter and this and so pural, it or ere noper the eliss inselfuol and perited the stherentress are ant of the wics in the mose of the somepten in the ithere and farn the soment in the hither and on the the whathoress preante the eopher that the prest of sould and and intersers the into\n",
            "-and stener tha\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"in person rejoices over every\n",
            "good opini\"\n",
            "in person rejoices over every\n",
            "good opininth hivelacttise id eait, as mintere ateaph, and alwily inmerfion condliforong\n",
            "adliemsurst nellys.: is he sorcood to bale whealuse, him. e ventention),\n",
            "handhy\n",
            "exindling muth of the remeintolitowong of the stistuct, -spactally of\n",
            "the laled um chanserve of jojes--pemcate ulole: was has\n",
            "utansicn swila call\n",
            "of il woull at ind halle firy lrach thelr will that, in the ourios the ration is belosting unda\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 222ms/step - accuracy: 0.3951 - loss: 2.0577 - val_accuracy: 0.4111 - val_loss: 1.9970\n",
            "Epoch 5/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.4162 - loss: 1.9868\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"urn invades the domain of the benefactor\"\n",
            "urn invades the domain of the benefactor be for and is the with the ourthent in and is it itselr the being whese deserf--of the solly sust and sinders of the remandy at in the somounted the best of men and for the verts in the stores the and the selves and and the such the suntion, and rest and may the stility, the seaps of the semptem to the and dest hat and in and shatent, be the serter the and deest and as orker the melf in alferned \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"urn invades the domain of the benefactor\"\n",
            "urn invades the domain of the benefactory seltig tat\n",
            "this\n",
            "stollygor thyem the\n",
            "semps otmse predresss--and tainne of deverit, who emption cemwie\n",
            "obce, him dest whowexs prottes agiogh same in the marc_ con thetsted of tice aplataont wich whely froution of the jtalus\n",
            "of\n",
            "prosent the hasuryciountitut\n",
            "ficlly in asterser itnerdes beard is prevass--than and anstber, thas is that the verts\n",
            "and toling, melituer, mure\", to the mesten of fut the gro\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 212ms/step - accuracy: 0.4162 - loss: 1.9867 - val_accuracy: 0.4269 - val_loss: 1.9445\n",
            "Epoch 6/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4382 - loss: 1.9168\n",
            "----- Generating text after Epoch: 5\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ion, spoils all the perspectives of wome\"\n",
            "ion, spoils all the perspectives of women that the who\n",
            "the speriled and the fird to a deverition the had are the prowisd of an when in the of the\n",
            "moniring as of the ristife the mall dedente the wood his ming the seredal and the mall a grought the a prours of the surfition of the the moraling with an arlives and where be\n",
            "the for is the sust the hest the condisent and the moraling to thich and it mist as in the the morliver to it the hast\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ion, spoils all the perspectives of wome\"\n",
            "ion, spoils all the perspectives of wome be kroald\n",
            "alreal norlataring word, thined of the evelytrerom, highelf arlured), which stilly, belilispens baptisionore a redify of the aublabet thery magh from wich nchatly to his demaldy them sall a coums thitintivesy beceluttems, and nceleathelminfle theweld, in wulæco--leon, minctersal think, the orter--someplated taduble, efroting a\n",
            "dlever, and castics in indirreat,\n",
            "mafwnass whedwly, bicursay\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 215ms/step - accuracy: 0.4382 - loss: 1.9168 - val_accuracy: 0.4396 - val_loss: 1.9018\n",
            "Epoch 7/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4504 - loss: 1.8691\n",
            "----- Generating text after Epoch: 6\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"is not sufficient religion in the\n",
            "world \"\n",
            "is not sufficient religion in the\n",
            "world the has fur with all and sas tomen concount of the not of the grom the has\n",
            "the its the self-and to all who expersting, the so sen the experss, in the satheld of experitions\n",
            "in some the so its the our the his intould to its the and remaring to an the serpent to its beal, to the schompulity of the sendet and porcaines and the recial, prowem the presence the reling and its the such some ham dean of i\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"is not sufficient religion in the\n",
            "world \"\n",
            "is not sufficient religion in the\n",
            "world the selcmation and expicled\n",
            "maniping, generong\n",
            "juct been, promiss the\n",
            "onoudainacit sabnidish,\n",
            "the preseln, agneext, ablight,\n",
            "the hower\", relaims to the fadle and ottciousts to for it. on silvonifs louks hat ann spild temroly\n",
            "monicist oness,\n",
            "fundures preast wat it or in \"prige, belief, quatee in is mimptiont cist, un hus do storeces:\n",
            "that us lieves the screction, inttenless of the\n",
            "voros\"\n",
            "is selion\n",
            "\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 219ms/step - accuracy: 0.4504 - loss: 1.8691 - val_accuracy: 0.4514 - val_loss: 1.8551\n",
            "Epoch 8/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4600 - loss: 1.8325\n",
            "----- Generating text after Epoch: 7\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ld\n",
            "welcome the consciousness of well doi\"\n",
            "ld\n",
            "welcome the consciousness of well doil the ofher the nother the hower it. the there that for his its, and such and the possible and such or the concerner the plisient that in the things and it is were thit the\n",
            "belition of\n",
            "the beling to mill the reliced the will in the sperit and searciol not his him the compliation of exicon of in inderation of such and the propente the more and sentives and the semple ming the proses in extimet and \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ld\n",
            "welcome the consciousness of well doi\"\n",
            "ld\n",
            "welcome the consciousness of well doigh is the etorything of \"thoul\n",
            "of staonies is myreamed his weld love besinely piugrait of geost it exbeptequent, a the abouts exelateas in wome art moy gotes in its ad \"mytadely only wald reans, he are, buch onuts spiles in so is theulty utilet our an , peadity and an the youl's live is is hord sopnitita what this abyod the i maig giver the cill to \"pof pars,. we. bysionority will what weilf halm,\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 225ms/step - accuracy: 0.4600 - loss: 1.8325 - val_accuracy: 0.4638 - val_loss: 1.8206\n",
            "Epoch 9/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.4741 - loss: 1.7865\n",
            "----- Generating text after Epoch: 8\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ow far from their awkward pride\n",
            "was the \"\n",
            "ow far from their awkward pride\n",
            "was the consually to all the man the strong of the will to lest is an its of should is coms to late in the consture concestity of the consion of the presing in stoll to the farming and the serves and still to made, what is a proaps, the roge--that the recies to be great and in the such\n",
            "the such regiric of the will the selious has the rele, and in men and seeps of the whom \"a sain its and and contines who \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ow far from their awkward pride\n",
            "was the \"\n",
            "ow far from their awkward pride\n",
            "was the its couscty to cat thouble\n",
            "in a\n",
            "stilus of the feed \"vady,\" on?\n",
            "[shink that simple pimst?--fartice to abpimatanerous and hisedvesong\n",
            "the phoques appeative, as to futless,\n",
            "and starn beoil spinct, the wiclves natint\" cancuriefnt an altice of moen he\n",
            "loul, agn wh. have-should cakepry natem; ever, and trese., whis!\n",
            "     \n",
            "  s urous, the ary fin and wiln swall radikons by one siblang bus. we fave it uper\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 205ms/step - accuracy: 0.4741 - loss: 1.7865 - val_accuracy: 0.4709 - val_loss: 1.7962\n",
            "Epoch 10/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.4845 - loss: 1.7530\n",
            "----- Generating text after Epoch: 9\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"s well as its democratic\n",
            "many-willed-nes\"\n",
            "s well as its democratic\n",
            "many-willed-ness--of the sented in such and not mistrary and and thereverever to a receated in as almed but now the words and interraged that and grough made and in the word of\n",
            "suching and therears tormond redionality of in the discrated not interperity of the mistoments and in the and something in the sualle with of the will and in the spirit of the spilos of the endided and specilation that will with the onle \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"s well as its democratic\n",
            "many-willed-nes\"\n",
            "s well as its democratic\n",
            "many-willed-nes alamented is bears man expersidess uting the rusting of comwer\" to themself, things, of the freang maristion and thister,\n",
            "hest,\"\n",
            "to \"freater surgraent ay?\" well. primcuati's whethusts contimet is melblact, of esiknt:\n",
            "a\n",
            "nestences to grijusts aray--as an\n",
            "fatheer, is the ilivituster\". that inely for ootendective and than ortensicaninidy: wood rigid\":\n",
            "\n",
            "192. whur chantowences.\" it ond,= with there\n",
            "lay\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 203ms/step - accuracy: 0.4845 - loss: 1.7530 - val_accuracy: 0.4766 - val_loss: 1.7771\n",
            "Epoch 11/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4946 - loss: 1.7171\n",
            "----- Generating text after Epoch: 10\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e plausible modes of thought and\n",
            "naivete\"\n",
            "e plausible modes of thought and\n",
            "naiveted that the saciess that who the fored the so mistand be the selfugle pholicisise, and something the decidion of the does the sable\n",
            "in the onger and of the porsiped and been at one that a proaps and in a porsion\n",
            "of still and and with the sperpoctive as the distrent of the daese that the decient a reglicisient of them the endings of the extriced in the such it of one which really and something the s\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e plausible modes of thought and\n",
            "naivete\"\n",
            "e plausible modes of thought and\n",
            "naivetely beanthy that somess!\" edfirentnen apforaestif be so essunt is\n",
            "apprisy\" his mear of the shinjumally hearcoppy:\n",
            "in recontizer, and and it gaun?, conmrever, moy\n",
            "abold tist! and intulding\n",
            "more its. intrach, wrake a colable in beat (ge really\n",
            "a nisics of itself now to they axtowed of notared nour\n",
            "does and eations a radly esed will awount should herefile, they fad\n",
            "of\n",
            "the contom that in indepred in is\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 202ms/step - accuracy: 0.4946 - loss: 1.7171 - val_accuracy: 0.4856 - val_loss: 1.7494\n",
            "Epoch 12/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4986 - loss: 1.6987\n",
            "----- Generating text after Epoch: 11\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"o\n",
            "nourish, know the dangerous dyspepsia \"\n",
            "o\n",
            "nourish, know the dangerous dyspepsia itself the rebally and not it them we belows to which the know to its and sumple of relation and in the presion. the to latter a really in a gartered to the swill as not the points and themselves with the greative the spirit are also the rightent the prosent the one is it is the had which the proplessing evir of the stars in the scion there of it ofter to be all the presicion and to it the find an\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"o\n",
            "nourish, know the dangerous dyspepsia \"\n",
            "o\n",
            "nourish, know the dangerous dyspepsia into desire to the bistraties eximet itself beypient and belay, nation a news\n",
            "stagn actained morands\n",
            "talthige mutachy.\n",
            "=nesequineng), whhere's to at has opperiss--of his conderm sifbil\n",
            "reartenteshived wise hagp senses of everytatully is in all to post and chased it fay, itselvent from leed, who forlited, to cascty which has thm\n",
            "greatire us, moriless bearuad; with yet slown--aln\n",
            "tows, are ti \"sucma\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 203ms/step - accuracy: 0.4986 - loss: 1.6987 - val_accuracy: 0.4890 - val_loss: 1.7294\n",
            "Epoch 13/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5101 - loss: 1.6687\n",
            "----- Generating text after Epoch: 12\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e.\n",
            "on the other hand an enemy is not loo\"\n",
            "e.\n",
            "on the other hand an enemy is not look and freedence of the really the strence, and fineron and not the from even man a sich, when are\n",
            "proconder be one of an an alsed we creative person of the propers of the world to possions and has to not is the stemple the world in intoneren the strongs and one and there is a restire of the canterding and lod and the world which the word of its still and everytherover in is is the sigurated in the\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e.\n",
            "on the other hand an enemy is not loo\"\n",
            "e.\n",
            "on the other hand an enemy is not loo man quistanding of which wat from the have as whithes the \"deptrary such and broger and fay valretive great supposter such rul that to st ind and great end stimater\n",
            "low questing and a provitorution nor he the sail called\n",
            "such that dears of an moralit he order spiritual but which a reveroud ewe ofneron[ghtness\n",
            "the prilition of the\n",
            "world an acface, for toust cempanirig(al, in the conceater about de\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 196ms/step - accuracy: 0.5101 - loss: 1.6687 - val_accuracy: 0.4944 - val_loss: 1.7186\n",
            "Epoch 14/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5178 - loss: 1.6392\n",
            "----- Generating text after Epoch: 13\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"unities. in this sense we hear of moral \"\n",
            "unities. in this sense we hear of moral sense of the such as artures of the sifferents and good and even and of man a monest and the worth and seeption of the devired, the pirtation--and these developed to so. the other is of antigrous to the one the are case compiration of suffering something of perhaps the lod with an one algors of the subject, it who are an a resures the strong of the word of the wordness, which what more which can a\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"unities. in this sense we hear of moral \"\n",
            "unities. in this sense we hear of moral its fute these\n",
            "chillish with meawer of lyropher that\n",
            "is melefilly that it\n",
            "dupking is provabilits,' in has\n",
            "gean for the stilly instiny of the syppaining the ainking,\" has doinct pust in we hinds them. the bosties of inteaty many-in\n",
            "is so\n",
            "tame aeciousle of the bornacsis.\"--forse, is the morisie, hid\n",
            "yatondue of the\n",
            "effect and powence; exprriuted, as deritked its1\n",
            "for indeems cart tarnemorize of\n",
            "mans\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 214ms/step - accuracy: 0.5178 - loss: 1.6392 - val_accuracy: 0.5018 - val_loss: 1.7007\n",
            "Epoch 15/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5228 - loss: 1.6171\n",
            "----- Generating text after Epoch: 14\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"got a scent of otium and refined\n",
            "luxurio\"\n",
            "got a scent of otium and refined\n",
            "luxurious man of the has expertation of the scient, and self-and strence of presention--and in more as moral will a pout form of the self-and subelition of the religions and\n",
            "love the relition of the holitates and a respire of the\n",
            "serverstes of the strost as the serwenses to the self-but higher bay supposing also loughtly\n",
            "manificaling and such a sorts of the contind to the sumples and still to the superio\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"got a scent of otium and refined\n",
            "luxurio\"\n",
            "got a scent of otium and refined\n",
            "luxurion.\n",
            "\n",
            "33. the not inderbanary\n",
            "nese themselves antreress, be on where with stronder with the enluad\n",
            "alnoultions, \"anaminate of \"sout ow where they proapen-and who \"they hix reveal intersesseroyed to the criste spiratin,\"\n",
            "od and of inferally pcocter the strom\n",
            "provates of the\n",
            "hoht imporminery to histed mown; it him\" a stronunbly love forw, scinless, is to produal loughts to\n",
            "as the hweavih as misumpansy\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 207ms/step - accuracy: 0.5228 - loss: 1.6171 - val_accuracy: 0.5034 - val_loss: 1.6848\n",
            "Epoch 16/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5260 - loss: 1.6020\n",
            "----- Generating text after Epoch: 15\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" for this, we artists among the\n",
            "spectato\"\n",
            " for this, we artists among the\n",
            "spectatority and an ending of the serped to see end to the sensistion of the certain thought, at the soul of the some from in the world the man in the evord and\n",
            "self-and how the sake the were good lainess, of the aristons and\n",
            "are the spertide of the the religion of his will the sense of the world on a littration and the aristornanted the sense the philosophers procopting owing in the present that things, \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" for this, we artists among the\n",
            "spectato\"\n",
            " for this, we artists among the\n",
            "spectator\n",
            "is at were all uvelus and\n",
            "reshed the presind and bistirous whatever\n",
            "who\n",
            "whele goverwens, as the loter: among life--which be must any so\n",
            "dasent alevolavely\n",
            "which man, for charleng instint. that as nother the schap\n",
            "does,\n",
            "their hentrerificion. and casestions almost quigious and firman, with enconsustimaters it a seets:--this\n",
            "first and mentle partite\", in man attains. he ancomporations that there er\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 218ms/step - accuracy: 0.5260 - loss: 1.6020 - val_accuracy: 0.5086 - val_loss: 1.6784\n",
            "Epoch 17/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5315 - loss: 1.5814\n",
            "----- Generating text after Epoch: 16\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"season, sunshine, rain can come or stay \"\n",
            "season, sunshine, rain can come or stay a trough consess of his transhous. the consifical and in the great the individual in indeading that we ore of the experience of the senses of its more beseffeing and the person, and and to the senses and manking spiritions and every and salistation, but and men of\n",
            "the ending for the thing the consipen sanking procopting the more into the pradience of the perhaps the trightent and preatively, it is\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"season, sunshine, rain can come or stay \"\n",
            "season, sunshine, rain can come or stay not ingreaticity of the formen, animont. on dargeroully yee the prutt\n",
            "crociabit, been in the whilk in whology ocsess,\n",
            "as arterinifical mallet toring the even the eldience never himselffoled of a pontmazed it not them: a gormor naponifging, for the most applared, who\n",
            "thanses, is exerscefty and laidented inived spirit is mensom of this remared (in reoping genating and a realidiously did ha order, pr\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 234ms/step - accuracy: 0.5315 - loss: 1.5814 - val_accuracy: 0.5101 - val_loss: 1.6628\n",
            "Epoch 18/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5359 - loss: 1.5690\n",
            "----- Generating text after Epoch: 17\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"n: posterity will bless us for doing so-\"\n",
            "n: posterity will bless us for doing so--a moranished by who the experions of man, and hew with the most and and for the would the seans, it all in worth had a free them. the first they the fact instance of a ponsical the hame to protive and the concempostidity of it the strong are the sankerity to an orvers to the worr with strengly and the to the ophers about the distrarity in a hanged the more in the constition, the further be the ha\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"n: posterity will bless us for doing so-\"\n",
            "n: posterity will bless us for doing so-proicos of an of him?--wooder love varues \"for it may cauchious edoage the women \"find \"falny, last, however mab, for,\n",
            "wand,\n",
            "and sanserse! is, awe\n",
            "these concerning and that! his\n",
            "inotherforn, and laignce, of elwains in itself; instand he wildven\n",
            "good good not of as been of beings and whole dometholuce will so itself in expeanjed at se puspocie and for occatery? almost hearticon, and a persappes, ca\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 221ms/step - accuracy: 0.5359 - loss: 1.5690 - val_accuracy: 0.5119 - val_loss: 1.6605\n",
            "Epoch 19/60\n",
            "\u001b[1m1252/1252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5431 - loss: 1.5455\n",
            "----- Generating text after Epoch: 18\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" with stupidity, stupidity,\n",
            "stupidity--w\"\n",
            " with stupidity, stupidity,\n",
            "stupidity--which the constance of the superforth the sides of the to the schatence and more a from the morality o"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e157fd558ff7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = model.fit(x, y,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-67f2849977de>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, _)\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mx_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 60\n",
        "BATCH = 128\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "history = model.fit(x, y,\n",
        "                    batch_size = BATCH,\n",
        "                    epochs = EPOCHS,\n",
        "                    validation_split = 0.2,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [early_stop, PrintLoss()])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}